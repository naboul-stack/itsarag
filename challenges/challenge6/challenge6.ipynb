{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 6: Actions\n",
    "## Introduction\n",
    "\n",
    "In this part of the challenge you will add another agent to the solution.\n",
    "\n",
    "This time will be an agent that performs actions on behalf of the user.\n",
    "\n",
    "## Step 1: Setup the final enviroment\n",
    "\n",
    "## Step 2: Build on top of the previous solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "## Import the necessary libraries\n",
    "\n",
    "import requests\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from urllib.parse import quote_plus \n",
    "from its_a_rag import ingestion\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.agents import AgentExecutor, create_sql_agent, create_openai_tools_agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment Variables\n",
    "\n",
    "**Important:** Make sure you update your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv, sys\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "\n",
    "# Setup environment\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "AZURE_SEARCH_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Local Folder for the documents\n",
    "LOCAL_FOLDER = \"D:\\fsi2023\"\n",
    "\n",
    "# SQL Database\n",
    "SQL_SERVER = os.getenv(\"SQL_SERVER\")\n",
    "SQL_DB = os.getenv(\"SQL_DB\")\n",
    "SQL_USERNAME = os.getenv(\"SQL_USERNAME\")\n",
    "SQL_PWD = os.getenv(\"SQL_PWD\")\n",
    "\n",
    "# STOCK API\n",
    "MOCK_API_ENDPOINT= os.getenv(\"MOCK_API_ENDPOINT\")\n",
    "\n",
    "# Define the questions list (if you are using your own dataset you need to change this list)\n",
    "QUESTIONS = [\n",
    "  \"What are the revenues of GOOGLE in the year 2009?\",\n",
    "  \"What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\",\n",
    "  \"Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\",\n",
    "  \"Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\",\n",
    "  \"Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\",\n",
    "  \"What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\",\n",
    "  \"What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\",\n",
    "  \"Can you buy 10 shares of APPLE for me?\"\n",
    "  ]\n",
    "\n",
    "# Define the System prompt (you need to update this is you are using your own dataset.)\n",
    "system_prompt_RAG = \"\"\" You are a financial assistant tasked with answering questions related to the financial results of major technology companies listed on NASDAQ, \\n\n",
    "specifically Microsoft (MSFT), Alphabet Inc. (GOOGL), Nvidia (NVDA), Apple Inc. (AAPL), and Amazon (AMZN). \\n\n",
    "if you don't find the answer in the context, just say `I don't know.`\"\"\"\n",
    "\n",
    "system_prompt_START = \"\"\"\n",
    "  You are an agent that needs analyze the user question. \\n\n",
    "  Question : {input} \\n\n",
    "  if the question is related to stock prices answer with \"stock\". \\n\n",
    "  if the question is related to information about financial results answer with \"rag\". \\n\n",
    "  if the question is unclear or you cannot decide answer with \"rag\". \\n\n",
    "  only answer with one of the word provided.\n",
    "  Your answer (stock/rag):\n",
    "  \"\"\"\n",
    "system_prompt_SQL = \"\"\"\n",
    "  You are a helpful AI assistant expert in querying SQL Database to find answers to user's question about stock prices.\n",
    "  If you can't find the answer, say 'I am unable to find the answer.'\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build on top of the previous solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    temperature=0,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "# this should include the input, output and decision as strings\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Agent - This agent should be copied from challenge 5\n",
    "\n",
    "def stock_agent(state):\n",
    "",
    "    # Create the DB Connection\n",
    "    engine = create_engine(f\"mssql+pymssql://{SQL_USERNAME}:{SQL_PWD}@{SQL_SERVER}:1433/{SQL_DB}\")\n",
    "    # Create the SQL Database Object and the SQL Database Toolkit Object to be used by the agent.\n",
    "    db = SQLDatabase(engine=engine)\n",
    "",
    "    # Create the agent using the Langhcain SQL Agent Class (create_sql_agent)\n",
    "",
    "    # Structure the final prompt from the ChatPromptTemplate\n",
    "",
    "    # Prepare the response using the invoke method of the agent\n",
    "",
    "    # Return the response for the next agent (output and input required coming fron the Agent State)\n",
    "    return {\"output\": response['output'], \"input\": state[\"input\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node rag - This RAG agent should be copied from challenge 5\n",
    "\n",
    "def rag_agent(state):\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the Stock Action Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node stock_action\n",
    "# Define the tool using the @tool decorator\n",
    "@tool\n",
    "def buy_stocks(quantity: int, symbol: str) -> str:\n",
    "",
    "\n",
    "\n",
    "@tool\n",
    "def sell_stocks(quantity: int, symbol: str) -> str:\n",
    "",
    "\n",
    "\n",
    "# You can combine multiple tools in a single block called Toolkit\n",
    "",
    "\n",
    "def stock_action(state):\n",
    "    # Define the LLM\n",
    "",
    "    # Prepare the prompt for the agent (the create_openai_tools_agent function requires a ChatPromptTemplate object)\n",
    "    # Prompt Example: \"You are an agent that helps to acquire stocks. Use your tools to perform the requested action. \\n if you can't perform the action, say 'I am unable to perform the action.' \\n\"\n",
    "",
    "    # Construct the OpenAI Tools Agent\n",
    "",
    "    # Prepare the Agent Executor\n",
    "",
    "    # prepare the response using the invoke method of the agent\n",
    "",
    "    # Return the response for the next agent (output and input required coming from the Agent State)\n",
    "",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Update the Start Agent adding an addition decision answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the start_agent that analyze the user question and decide if the question is related to stock prices or financial results - this is an updated from what you created in challenge 5\n",
    "def start_agent(state):\n",
    "    # Import the global llm\n",
    "",
    "    # Prepare the prompt for the agent\n",
    "",
    "    # Prepare the chain to be executed\n",
    "",
    "    # Invoke the chain\n",
    "",
    "    # Take the decision from the response\n",
    "",
    "    # Return the response for the next agent (decision and input required coming fron the Agent State)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update the previous graph to include the new agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "# this should include the input, output and decision as strings\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "\n",
    "# Create the 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "# Add nodes (start_agent, stock_agent, rag_agent) and conditional edges where the decision with be stock or rag\n",
    "def create_graph():\n",
    "    # Create the Workflow as StateGraph using the AgentState\n",
    "",
    "    # Add the nodes (start_agent, stock_agent, rag_agent)\n",
    "",
    "    # Add the conditional edge from start -> lamba (decision) -> stock_agent or rag_agent\n",
    "",
    "    # Set the workflow entry point\n",
    "",
    "    # Add the final edges to the END node\n",
    "",
    "    # Compile and return the workflow\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Solution\n",
    "\n",
    "# intantiate the graph (create_graph)\n",
    "graph = create_graph()\n",
    "\n",
    "# Use the graph invoke to answer the questions\n",
    "# Test the graph with various questions\n",
    "\n",
    "for QUESTION in QUESTIONS:\n",
    "    print (QUESTION)\n",
    "    result = graph.invoke({\"input\": QUESTION})\n",
    "    print(result[\"output\"])\n",
    "    print (\"------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}